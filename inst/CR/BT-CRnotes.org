#+TITLE: Explicit formula for the net benefit
#+Author: Brice Ozenne, Julien PÃ©ron


\clearpage

* Parameter of interest

Let consider two independent real valued random variables \(X\) and \(Y\).
We are interested in:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = \Prob[Y>X] - \Prob[X>Y]
\end{align*}
#+END_EXPORT

\bigskip

In the examples we will use a sample size of:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
n <- 1e4
#+END_SRC

#+RESULTS:

and use the following R packages
#+BEGIN_SRC R :exports code :results silent :session *R* :cache no
library(BuyseTest)
library(riskRegression)
library(survival)
#+END_SRC

\clearpage

* Binary variable
** Relationship between \(\Delta\) and the prevalence
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] = \Prob[Y=1,X=0]
\end{align*}
#+END_EXPORT
Using the independence between \(Y\) and \(X\):
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] = \Prob[Y=1]\Prob[X=0] = \Prob[Y=1](1-\Prob[X=1]) = \Prob[Y=1] - \Prob[Y=1]\Prob[X=1]
\end{align*}
#+END_EXPORT
By symmetry:
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[X>Y] = \Prob[X=1] - \Prob[Y=1]\Prob[X=1]
\end{align*}
#+END_EXPORT
So 
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = \Prob[Y=1] - \Prob[X=0]
\end{align*}
#+END_EXPORT

** In R
Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
prob1 <- 0.4
prob2 <- 0.2
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(tox = rbinom(n, prob = prob1, size = 1), group = "C"),
            data.frame(tox = rbinom(n, prob = prob2, size = 1), group = "T"))
#+END_SRC

#+RESULTS:

Buyse test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
BuyseTest(group ~ bin(tox), data = df, method.inference = "none", trace = 0)
#+END_SRC
#+RESULTS:
:  endpoint threshold   delta   Delta
:       tox       0.5 -0.1981 -0.1981

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
prob2 - prob1
#+END_SRC

#+RESULTS:
: [1] -0.2

\clearpage

* Continuous variable
** Relationship between \(\Delta\) and Cohen's d
Let's consider two independent normally distributed variables with common variance:
- \(X \sim \Gaus[\mu_X,\sigma^2]\) 
- \(Y \sim \Gaus[\mu_Y,\sigma^2]\) 
Denoting \(d = \frac{\mu_Y-\mu_X}{\sigma}\): 
- \(X^* \sim \Gaus[0,1]\) 
- \(Y^* \sim \Gaus[d,1]\) 
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] &= \Esp \left[ \Ind[Y>X] \right] = \Esp\left[ \Ind[Y*>X*] \right] = \Esp\left[ \Ind[Z>0] \right]
\end{align*}
#+END_EXPORT
where \(Z \sim \Gaus[d,2]\) so \(\Prob[Y>X] = \Phi(\frac{d}{\sqrt{2}})\)

By symmetry
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = 2*\Phi(\frac{d}{\sqrt{2}})-1
\end{align*}
#+END_EXPORT

** In R

Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
meanX <- 0
meanY <- 2
sdXY <- 1
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(tox = rnorm(n, mean = meanX, sd = sdXY), group = "C"),
            data.frame(tox = rnorm(n, mean = meanY, sd = sdXY), group = "T"))
#+END_SRC

#+RESULTS:

Buyse test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
BuyseTest(group ~ cont(tox), data = df, method.inference = "none", trace = 0)
#+END_SRC

#+RESULTS:
:  endpoint threshold  delta  Delta
:       tox     1e-12 0.8359 0.8359

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
d <- (meanY-meanX)/sdXY
2*pnorm(d/sqrt(2))-1
#+END_SRC

#+RESULTS:
: [1] 0.8427008

\clearpage

* Survival
** Relationship between \(\Delta\) and the hazard ratio
For a given cumulative density function \(F(x)\) and a corresponding
probability density function \(f(x)\) we define the hazard by:
#+BEGIN_EXPORT latex
\begin{align*}
\lambda(t) &=  \left. \frac{\Prob[t\leq T \leq t+h|T\geq t]}{h}\right|_{h \rightarrow 0^+} \\
&= \left. \frac{\Prob[t\leq T \leq t+h]}{\Prob[T\geq t]h}\right|_{h \rightarrow 0^+} \\
&= \frac{f(t)}{1-F(t)}
\end{align*}
#+END_EXPORT

\bigskip

Let now consider two times to events following an exponential distribution:
- \(X \sim Exp(\alpha_1)\). The corresponding hazard function is \(\lambda(t)=\alpha_1\).
- \(Y \sim Exp(\alpha_2)\). The corresponding hazard function is \(\lambda(t)=\alpha_2\).
So the hazad ratio is \(HR = \frac{\lambda_2}{\lambda_1}\). Note that if we use a cox model we will have:
#+BEGIN_EXPORT latex
\begin{align*}
\lambda(t) = \lambda_0(t) \exp(\beta \Ind[group])
\end{align*}
#+END_EXPORT
where \(\exp(\beta)\) is the hazard ratio.

\bigskip

#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] &= \int_{0}^{\infty}\alpha_1 \exp(-\alpha_1 x)  \int_x^{\infty} \alpha_2 \exp(-\alpha_2 y) dy dx \\
&= \int_{0}^{\infty}\alpha_1 \exp(-\alpha_1 x)  [ \exp(-\alpha_2 y) ]_{\infty}^{x} dx \\
&= \int_{0}^{\infty}\alpha_1 \exp(-\alpha_1 x) \exp(-\alpha_2 x) dx \\
&= \frac{\alpha_1}{\alpha_1+\alpha_2} [\exp(-(\alpha_1+\alpha_2) x)]_{\infty}^{0} \\
&= \frac{\alpha_1}{\alpha_1+\alpha_2}\\
&= \frac{1}{1+HR}\\
\end{align*}
#+END_EXPORT

So:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = 2\frac{1}{1+HR}-1 = \frac{1-HR}{1+HR}
\end{align*}
#+END_EXPORT

** Scoring rule in presence of censoring
Let's consider the following random variables:  
- \(X\) the time to the occurrence of the event of interest in the treatment group.
- \(C_X\) the censoring time in the treatment group.
- \(X^* = X \wedge C_X\) the observed event time in the treatment group.
- \(\varepsilon_X = \Ind[X \leq C_X]\) the event time indicator in the treatment group.
- \(Y\) the time to the occurrence of the event of interest in the control group.
- \(C_Y\) the censoring time in the control group.
- \(Y^* = Y \wedge C_Y\) the observed event time in the control group.
- \(\varepsilon_Y = \Ind[Y \leq C_Y]\) the event time indicator in the control group.

We observe one realization \(\left(x^*, y^*, e_X, e_Y \right)\) of the
random variables \(\left(X^*, Y^*, \varepsilon_X, \varepsilon_Y
\right)\). We use the short notation \(x \wedge y = min(x,y)\) and \(x \vee y = max(x,y)\).

*** Case: \(e_X=0,e_Y=1\)

*Probability in favor of the treatment*:
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[x \geq y + \tau | x \geq x^*, y = y^*] 
&= \frac{ \Prob[x \geq y^* + \tau, x \geq x^*] }{ \Prob[x \geq x^*]} \\
&= \frac{ \Prob[x \geq max(y^* + \tau,x^*)] }{\Prob[x \geq x^*]} \\
&= \frac{ S_X(y^* + \tau \vee x^*)}{S_X(x^*)}
\end{align*}
#+END_EXPORT

In the case where \(x^* < y^* + \tau\), we need an estimate of
\(S_X(y^* + \tau)\) to compute the probability in favor of the
treatment. If we can only have an estimate of \(S_X\) up to
\(x_{max} < y^* + \tau\) then we can use the following inequality:
#+BEGIN_EXPORT latex
\begin{align*}
S_X(y^* + \tau) &\geq 0 \\
\Prob[x \geq y + \tau | x \geq x^*, y = y^*] &\geq 0 \\
\end{align*}
#+END_EXPORT

*Probability in favor of the control*:

#+BEGIN_EXPORT latex
\begin{align*}
\Prob[y \geq x + \tau | x \geq x^*, y = y^*] 
&= 1 - \frac{ \Prob[x \geq y^* - \tau, x \geq x^*] }{ \Prob[x \geq x^*]} \\
&= 1 - \frac{ \Prob[x \geq max(y^* - \tau,x^*)] }{\Prob[x \geq x^*]} \\
&= 1 - \frac{ S_X(y^* - \tau \vee x^*)}{S_X(x^*)}
\end{align*}
#+END_EXPORT

In the case where \(x^* < y^* - \tau\), we need an estimate of
\(S_X(y^* - \tau)\) to compute the probability in favor of the
control. If we can only have an estimate of \(S_X\) up to
\(x_{max} < y^* - \tau\) then we can use the following inequality:
#+BEGIN_EXPORT latex
\begin{align*}
S_X(x_{max}) &\geq S_X(y^* - \tau) \\
\Prob[x \geq y - \tau | x \geq x^*, y = y^*] &\geq 1 - \frac{ S_X(x_{max})}{S_X(x^*)} \\
\end{align*}
#+END_EXPORT

*Probability of being neutral*:

#+BEGIN_EXPORT latex
\begin{align*}
\Prob[|x-y| \leq \tau | x \geq x^*, y = y^*] 
&= 1-\Prob[x \geq y + \tau | x \geq x^*, y = y^*]-\Prob[y \geq x + \tau | x \geq x^*, y = y^*]  \\
&= \frac{ S_X(y^* - \tau \vee x^*) - S_X(y^* + \tau \vee x^*)}{S_X(x^*)}
\end{align*}
#+END_EXPORT

Consider the case \(  x^*\)
If \(x_{max} > y^* - \tau\) then 
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[|x-y| \leq \tau | x \geq x^*, y = y^*] \geq \frac{ S_X(y^* - \tau) - S_X(x_{max})}{S_X(x^*)}
\end{align*}
#+END_EXPORT
otherwise
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[|x-y| \leq \tau | x \geq x^*, y = y^*] \geq 0
\end{align*}
#+END_EXPORT

*Probability of being uninformative*: It is computed as the complement
to 1 of the sum of the probability of being in favor of the treatment,
in favor of the control, and neutral.

\bigskip

\textsc{Example}:

- when \(x^* > y^* + \tau\), the probability of being favorable is 1
  so the probability of being uninformative is 0.

- when \(\left|x^* - y^*\right| < \tau\), the probability of being in
  favor of the control is 0. If we know the survival in the treatment
  group up to time \(y^*\), then we can only say that the probability
  of being favorable is bounded below by 0. The probability of being
  neutral bounded below by \(1-S_T(y^*)/S_T(x^*)\). The probability of
  being uninformative is then \(S_T(y^*)/S_T(x^*)\). Clearly this
  probability becomes small when \(S_T(y^*)\) is small. The
  approximation by the lower bound becomes exact when \(S_T(y^*)\)
  tends to 0.
 
** In R

Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alphaX <- 2
alphaY <- 1
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(time = rexp(n, rate = alphaX), group = "C", event = 1),
            data.frame(time = rexp(n, rate = alphaY), group = "T", event = 1))
#+END_SRC

#+RESULTS:

Buyse test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
BuyseTest(group ~ tte(time, censoring = event), data = df,
          method.inference = "none", trace = 0, method.tte = "Gehan")
#+END_SRC
#+RESULTS:
:  endpoint threshold  delta  Delta
:      time     1e-12 0.3403 0.3403

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.coxph <- coxph(Surv(time,event)~group,data = df)
HR <- as.double(exp(coef(e.coxph)))
c("HR" = alphaY/alphaX, "Delta" = 2*alphaX/(alphaY+alphaX)-1)
c("HR.cox" = HR, "Delta" = (1-HR)/(1+HR))
#+END_SRC

#+RESULTS:
:        HR     Delta 
: 0.5000000 0.3333333
:    HR.cox     Delta 
: 0.4918256 0.3406392

\clearpage

* Competing risks

** Theory

*** General case (no censoring)
Let consider: 
- \(X^*_{E}\) the time to the occurrence of the event of interest in the control group.
- \(Y^*_{E}\) the time to the occurrence of the event of interest in the treatment group.
- \(X^*_{CR}\) the time to the occurrence of the competing event of interest in the control group.
- \(Y^*_{CR}\) the time to the occurrence of the competing event of interest in the treatment group.
Let denote \(\varepsilon_X = 1 +\Ind[X^*_{E} > X^*_{CR}]\) the event type
indicator in the control group and \(\varepsilon_Y = 1 + \Ind[Y^*_{E} >
Y^*_{CR}]\) the event type indicator in treatment group (\(=1\) when the
cause of interest is realised first and 2 when the competing risk is
realised first).

\bigskip

For each subject either the event of interest or the competing event
is realized. We now define:
#+BEGIN_EXPORT latex
\begin{align*}
X = \left\{
              \begin{array}{ll}
                 X^*_{E} \text{ if }\varepsilon_X = 1  \\
                 +\infty \text{ if }\varepsilon_X = 2 
                \end{array}
              \right.
\text{ and }
Y = \left\{
              \begin{array}{ll}
                 Y^*_{E} \text{ if }\varepsilon_Y = 1  \\
                 +\infty \text{ if }\varepsilon_Y = 2 
                \end{array}
              \right.
\end{align*}
#+END_EXPORT
i.e. when the event of interest is not realized we say that the time to event is infinite.

\bigskip

We thus have:
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y > X] 
= & \Prob[Y > X|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] \\
&+ \Prob[Y > X|\varepsilon_X=1,\varepsilon_Y=2]\Prob[\varepsilon_X=1,\varepsilon_Y=2] \\
&+ \Prob[Y > X|\varepsilon_X=2,\varepsilon_Y=1]\Prob[\varepsilon_X=2,\varepsilon_Y=1] \\
&+ \Prob[Y > X|\varepsilon_X=2,\varepsilon_Y=2]\Prob[\varepsilon_X=2,\varepsilon_Y=2] \\
= & \Prob[Y > X|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] \\
&+ 1*\Prob[\varepsilon_X=1,\varepsilon_Y=2] \\
&+ 0*\Prob[\varepsilon_X=2,\varepsilon_Y=1] \\
&+ 0*\Prob[\varepsilon_X=2,\varepsilon_Y=2] \\
\end{align*}
#+END_EXPORT

So \(\Prob[X > Y] = \Prob[X >
Y|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] +
\Prob[\varepsilon_X=1,\varepsilon_Y=2] \) and:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = &
 \big(\Prob[X > Y|\varepsilon_X=1,\varepsilon_Y=1] - \Prob[X < Y|\varepsilon_X=1,\varepsilon_Y=1] \big) \Prob[\varepsilon_X=1,\varepsilon_Y=1] \\
& + \Prob[\varepsilon_X=1,\varepsilon_Y=2] - \Prob[\varepsilon_X=2,\varepsilon_Y=1]
\end{align*}
#+END_EXPORT

*** General case (censoring, method: Gehan)
In case of censoring we can use an inverse probability weighting
approach. Let denote \(\delta_{c,X}\) (resp. \(\delta_{c,Y}\)) the
indicator of no censoring relative to \(\tilde{X}\) (resp \(\tilde{Y}\)), \(\tilde{X}_E\) and \(\tilde{Y}_E\) the
censored event time. We can use inverse probability weighting to
compute the net benefit:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta^{IPW} &= \frac{\delta_{c,\tilde{X}}\delta_{c,\tilde{Y}}}{\Prob[\delta_{c,\tilde{X}}]\Prob[\delta_{c,\tilde{Y}}]} (\Ind[\tilde{Y}>\tilde{X}]-\Ind[\tilde{Y}<\tilde{X}])\\
&= \left\{
                \begin{array}{ll}
                  \frac{1}{\Prob[\delta_{c,\tilde{X}}]\Prob[\delta_{c,\tilde{Y}}]} (\Ind[Y>X]-\Ind[Y<X])\text{, if no censoring}\\
                  0\text{, if censoring}
                \end{array}
              \right.
\end{align*}
#+END_EXPORT

This is equivalent to weight the informative pairs (i.e. favorable,
unfavorable and neutral) by the inverse of the complement of the
probability of being uninformative. This is what is done by the
argument =correction.tte= of =BuyseTest=. This works whenever the
censoring mechanism is independent of the event times and we have a
consistent estimate of \(\Prob[\delta_c]\) since:
#+BEGIN_EXPORT latex
\begin{align*}
\Esp[\Delta^{IPW}] &= \Esp\left[ \Esp\left[ \frac{\delta_{c,\tilde{X}}\delta_{c,\tilde{Y}}}{\Prob[\delta_{c,\tilde{X}}]\Prob[\delta_{c,\tilde{Y}}]} (\Ind[\tilde{Y}>\tilde{X}]-\Ind[\tilde{Y}<\tilde{X}]) \Bigg| \tilde{X}, \tilde{Y} \right] \right]\\
&= \Esp\left[\Esp\left[\frac{\delta_{c,\tilde{X}}\delta_{c,\tilde{Y}}}{\Prob[\delta_{c,\tilde{X}}]\Prob[\delta_{c,\tilde{Y}}]} \Bigg| \tilde{X}, \tilde{Y} \right]\right] \Esp\left[\Ind[Y>X]-\Ind[Y<X]\right]\\
&= \frac{\Esp\left[\delta_{c,\tilde{X}}\delta_{c,\tilde{Y}} \right]}{\Prob[\delta_{c,\tilde{X}}]\Prob[\delta_{c,\tilde{Y}}]} \Delta
= \frac{\Esp[\delta_{c,\tilde{X}}]\Esp[\delta_{c,\tilde{Y}}]}{\Prob[\delta_{c,\tilde{X}}]\Prob[\delta_{c,\tilde{Y}}]} \Delta\\
&= \Delta
\end{align*}
#+END_EXPORT
where we used the law of total expectation (first line) and the independence between the censoring mecanisms.

*** Exponential distribution (no censoring)

Now let's assume that:
- \(X_{E} \sim Exp(\alpha_{E,X})\).
- \(Y_{E} \sim Exp(\alpha_{E,Y})\).
- \(X_{CR} \sim Exp(\alpha_{CR,X})\).
- \(Y_{CR} \sim Exp(\alpha_{CR,Y})\).

Then:
#+BEGIN_EXPORT latex
\begin{align*}
 \Prob[Y_{E} > X_{E}] &= \Prob[Y_{E} >
X_{E}|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] +
\Prob[\varepsilon_X=1,\varepsilon_Y=2] \\
&= \frac{1}{(\alpha_{E,X}+\alpha_{CR,X})(\alpha_{E,Y}+\alpha_{CR,Y})} \left(
 \alpha_{E,X}\alpha_{E,Y} \frac{\alpha_{E,X}}{\alpha_{E,X}+\alpha_{E,Y}}
+ \alpha_{E,X}\alpha_{CR,Y} \right) \\
\end{align*}
#+END_EXPORT


Just for comparison let's compare to the cumulative incidence. First
we only consider one group and two competing events whose times to
event follow an exponential distribution:
- \(T_E \sim Exp(\alpha_E)\). The corresponding hazard function is \(\lambda(t)=\alpha_E\).
- \(T_{CR} \sim Exp(\alpha_{CR})\). The corresponding hazard function is \(\lambda(t)=\alpha_{CR}\).
The cumulative incidence function can be written:
#+BEGIN_EXPORT latex
\begin{align*}
CIF_1(t) &= \int_0^t \lambda_1(s) S(s_-) ds \\
&= \int_0^t \alpha_E \exp(- (\alpha_E + \alpha_{CR}) * s_-) ds \\
&= \frac{\alpha_E}{\alpha_E + \alpha_{CR}} \left[ \exp(- (\alpha_E + \alpha_{CR}) * s_-)\right]_t^0 \\
&= \frac{\alpha_E}{\alpha_E + \alpha_{CR}} \left(1 - \exp(- (\alpha_E + \alpha_{CR}) * t_-)\right) 
\end{align*}
#+END_EXPORT
where \(S(t)\) denote the event free survival and \(s_-\) denotes the right sided limit.

\bigskip

Then applying this formula in the case of two groups gives:
#+BEGIN_EXPORT latex
\begin{align*}
CIF_1(t|group = X) &= \frac{\alpha_{E,X}}{\alpha_{E,X} + \alpha_{CR,X}} \left(1 - \exp(- (\alpha_{E,X} + \alpha_{CR,X}) * t_-)\right) \\
CIF_1(t|group = Y) &= \frac{\alpha_{E,Y}}{\alpha_{E,Y} + \alpha_{CR,Y}} \left(1 - \exp(- (\alpha_{E,Y} + \alpha_{CR,Y}) * t_-)\right) 
\end{align*}
#+END_EXPORT

** In R

*** BuyseTest (no censoring)

Setting:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alphaE.X <- 2
alphaCR.X <- 1
alphaE.Y <- 3
alphaCR.Y <- 2
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(time1 = rexp(n, rate = alphaE.X), time2 = rexp(n, rate = alphaCR.X), group = "1"),
            data.frame(time1 = rexp(n, rate = alphaE.Y), time2 = rexp(n, rate = alphaCR.Y), group = "2"))
df$time <- pmin(df$time1,df$time2) ## first event
df$event <- (df$time2<df$time1)+1 ## type of event
#+END_SRC

#+RESULTS:

BuyseTest:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.BT <- BuyseTest(group ~ tte(time, censoring = event), data = df,
                  method.inference = "none", method.tte = "Gehan",
                  trace = 0)
summary(e.BT, percentage = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example
        Generalized pairwise comparison with 1 prioritized endpoint

 > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
 > null hypothesis : Delta == 0 
 > treatment groups: 1 (control) vs. 2 (treatment) 
 > censored pairs  : uninformative pairs

 > results
 endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
     time     1e-12   100      41.6       45.12   13.28     0 -0.0352 -0.0352
#+end_example

Note that without censoring one can get the same results by treating
time as a continuous variable that take value \(\infty\) when the
competing risk is observed:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
df$timeXX <- df$time
df$timeXX[df$event==2] <- max(df$time)+1
e.BT.bis <- BuyseTest(group ~ cont(timeXX), data = df,
                  method.inference = "none", trace = 0)
summary(e.BT.bis, percentage = TRUE)
#+END_SRC

#+RESULTS:
:         Generalized pairwise comparison with 1 prioritized endpoint
: 
:  > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
:  > null hypothesis : Delta == 0 
:  > treatment groups: 1 (control) vs. 2 (treatment) 
:  > results
:  endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
:    timeXX     1e-12   100      41.6       45.12   13.28     0 -0.0352 -0.0352

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
weight <- (alphaE.X+alphaCR.X)*(alphaE.Y+alphaCR.Y)
exp <- list()
exp$favorable <- 1/weight*(alphaE.X*alphaE.Y*alphaE.X/(alphaE.X+alphaE.Y)+(alphaE.X*alphaCR.Y))
exp$unfavorable <- 1/weight*(alphaE.X*alphaE.Y*alphaE.Y/(alphaE.X+alphaE.Y)+(alphaE.Y*alphaCR.X))
exp$neutral <- alphaCR.X*alphaCR.Y/weight

100*unlist(exp)
#+END_SRC

#+RESULTS:
:   favorable unfavorable     neutral 
:    42.66667    44.00000    13.33333

# ## Flexible simulation of competing risks data following prespecified subdistribution hazards
# Subdistributional hazard:
# #+BEGIN_SRC R :exports both :results output :session *R* :cache no
# e.coxph <- coxph(Surv(timeXX, event==1) ~ group, data = df)
# HR.coxph <- as.double(exp(coef(e.coxph)))
# c("HR.sub" = HR.coxph, "Delta.sub" = (1-HR.coxph)/(1+HR.coxph))
# #+END_SRC

# #+RESULTS:
# :     HR.sub  Delta.sub 
# : 0.95597188 0.02250959

# # #+RESULTS:
# # :     HR.sub  Delta.sub 
# # : 0.97182195 0.01429036

# #+BEGIN_SRC R :exports both :results output :session *R* :cache no
# library(timereg)
# e.fg <- comp.risk(Event(time,event) ~ const(group), data = df, cause = 1, model = "fg",
#                   resample.iid = 1)
# summary(e.fg)
# HR.fg <- as.double(exp(coef(e.fg)[1]))
# c("HR.sub" = HR.fg, "Delta.sub" = (1-HR.fg)/(1+HR.fg))
# #+END_SRC

# #+RESULTS:
# : Competing risks Model 
# : 
# : No test for non-parametric terms
# : Parametric terms : 
# :               Coef.     SE Robust SE    z P-val lower2.5% upper97.5%
# : const(group)2 0.165 0.0195    0.0195 8.47     0     0.127      0.203
# :      HR.sub   Delta.sub 
# :  1.17939312 -0.08231334

*** BuyseTest (with censoring)

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
df$eventC <- df$event
df$eventC[rbinom(n, size = 1, prob = 0.2)==1] <- 0
#+END_SRC

#+RESULTS:

BuyseTest (biased):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.BTC <- BuyseTest(group ~ tte(time, censoring = eventC), data = df,
                   method.inference = "none", method.tte = "Gehan",
                   trace = 0)
summary(e.BTC, percentage = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example
        Generalized pairwise comparison with 1 prioritized endpoint

 > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
 > null hypothesis : Delta == 0 
 > treatment groups: 1 (control) vs. 2 (treatment) 
 > censored pairs  : uninformative pairs

 > results
 endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
     time     1e-12   100      31.1       35.15    8.65  25.1 -0.0406 -0.0406
#+end_example

BuyseTest (unbiased):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.BTCC <- BuyseTest(group ~ tte(time, censoring = eventC), data = df,
                   method.inference = "none", method.tte = "Gehan corrected",
                   trace = 0)
summary(e.BTCC, percentage = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example
        Generalized pairwise comparison with 1 prioritized endpoint

 > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
 > null hypothesis : Delta == 0 
 > treatment groups: 1 (control) vs. 2 (treatment) 
 > censored pairs  : uninformative pairs
                     IPW for uninformative pairs

 > results
 endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
     time     1e-12   100     41.52       46.94   11.54     0 -0.0542 -0.0542
#+end_example

*** Cumulative incidence

Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alphaE <- 2
alphaCR <- 1
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- data.frame(time1 = rexp(n, rate = alphaE), time2 = rexp(n, rate = alphaCR), group = "1", event = 1)
df$time <- pmin(df$time1,df$time2)
df$event <- (df$time2<df$time1)+1
#+END_SRC

#+RESULTS:

Cumulative incidence (via risk regression):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.CSC <- CSC(Hist(time, event) ~ 1, data = df)
vec.times <- unique(round(exp(seq(log(min(df$time)),log(max(df$time)),length.out = 12)),2))
e.CSCpred <- predict(e.CSC, newdata = data.frame(X = 1), time = vec.times , cause = 1)
#+END_SRC

#+RESULTS:

Expected vs. calculated:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
cbind(time = vec.times,
      CSC = e.CSCpred$absRisk[1,],
      manual = alphaE/(alphaE+alphaCR)*(1-exp(-(alphaE+alphaCR)*(vec.times)))
      )
#+END_SRC

#+RESULTS:
:      time    CSC     manual
: [1,] 0.00 0.0000 0.00000000
: [2,] 0.01 0.0186 0.01970298
: [3,] 0.02 0.0377 0.03882364
: [4,] 0.05 0.0924 0.09286135
: [5,] 0.14 0.2248 0.22863545
: [6,] 0.42 0.4690 0.47756398
: [7,] 1.24 0.6534 0.65051069
: [8,] 3.70 0.6703 0.66665659

Could also be obtained treating the outcome as binary:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mean((df$time<=1)*(df$event==1))
#+END_SRC

#+RESULTS:
: [1] 0.6375


# * References
# bibliographystyle:apalike
# [[bibliography:bibliography.bib]]

# @@latex:any arbitrary LaTeX code@@




* CONFIG :noexport:
# #+LaTeX_HEADER:\affil{Department of Biostatistics, University of Copenhagen, Copenhagen, Denmark}
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+OPTIONS:   title:t author:t toc:t todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t

** Code
#+PROPERTY: header-args :session *R*
#+PROPERTY: header-args :tange yes % extract source code: http://orgmode.org/manual/Extracting-source-code.html
#+PROPERTY: header-args :cache no
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}

** Display 
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\usepackage{authblk} % enable several affiliations (clash with beamer)

** Image
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files

** Latex command
#+LaTeX_HEADER: %
#+LaTeX_HEADER: %%%% additional latex commands %%%%
#+LaTeX_HEADER: %

** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}

** Math
#+LATEX_HEADER: \RequirePackage{ifthen}
#+LATEX_HEADER: \RequirePackage{xspace} % space for newcommand macro
#+LATEX_HEADER: \RequirePackage{xifthen}
#+LATEX_HEADER: \RequirePackage{xargs}
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)

# ## lemma
#+LaTeX_HEADER: \RequirePackage{amsthm}
#+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
#+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}

*** Template for shortcut
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }

*** Shortcuts

**** Probability
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}

#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}

#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}

**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}

#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}

#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}

#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\left( \partial #2\right)^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 

**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
