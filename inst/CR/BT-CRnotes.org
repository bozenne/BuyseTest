#+TITLE: Explicit formula for the net benefit
#+Author: Brice Ozenne, Julien PÃ©ron


\clearpage

* Parameter of interest

Let consider two independent real valued random variables \(X\) and \(Y\).
We are interested in:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = \Prob[Y>X] - \Prob[X>Y]
\end{align*}
#+END_EXPORT

\bigskip

In the examples we will use a sample size of:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
n <- 1e4
#+END_SRC

#+RESULTS:

and use the following R packages
#+BEGIN_SRC R :exports code :results silent :session *R* :cache no
library(BuyseTest)
librnary(riskRegression)
library(survival)
#+END_SRC

\clearpage

* Binary variable

** Theory
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] = \Prob[Y=1,X=0]
\end{align*}
#+END_EXPORT
Using the independence between \(Y\) and \(X\):
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] = \Prob[Y=1]\Prob[X=0] = \Prob[Y=1](1-\Prob[X=0]) = \Prob[Y=1] - \Prob[Y=1]\Prob[X=1]
\end{align*}
#+END_EXPORT
By symmetry:
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[X>Y] = \Prob[X=1] - \Prob[Y=1]\Prob[X=1]
\end{align*}
#+END_EXPORT
So 
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = \Prob[Y=1] - \Prob[X=0]
\end{align*}
#+END_EXPORT

** In R
Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
prob1 <- 0.4
prob2 <- 0.2
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(tox = rbinom(n, prob = prob1, size = 1), group = "C"),
            data.frame(tox = rbinom(n, prob = prob2, size = 1), group = "T"))
#+END_SRC

#+RESULTS:

Buyse test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
BuyseTest(group ~ bin(tox), data = df, method.inference = "none", trace = 0)
#+END_SRC
#+RESULTS:
:  endpoint threshold   delta   Delta
:       tox       0.5 -0.1981 -0.1981

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
prob2 - prob1
#+END_SRC

#+RESULTS:
: [1] -0.2

\clearpage

* Continuous variable

** Theory
Let's consider two normally distributed variables with common variance:
- \(X \sim \Gaus[\mu_X,\sigma^2]\) 
- \(Y \sim \Gaus[\mu_Y,\sigma^2]\) 
Denoting \(d = \frac{\mu_Y-\mu_X}{\sigma}\): 
- \(X^* \sim \Gaus[0,1]\) 
- \(Y^* \sim \Gaus[d,1]\) 
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] &= \Esp[\Ind[Y>X]] = \Esp[\Ind[Y*>X*]] = \Esp[\Ind[Z>0]]
\end{align*}
#+END_EXPORT
where \(Z \sim \Gaus[d,2]\) so \(\Prob[Y>X] = \Phi(\frac{d}{\sqrt{2}})\)

By symmetry
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = 2*\Phi(\frac{d}{\sqrt{2}})-1
\end{align*}
#+END_EXPORT

** In R

Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
meanX <- 0
meanY <- 2
sdXY <- 1
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(tox = rnorm(n, mean = meanX, sd = sdXY), group = "C"),
            data.frame(tox = rnorm(n, mean = meanY, sd = sdXY), group = "T"))
#+END_SRC

#+RESULTS:

Buyse test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
BuyseTest(group ~ cont(tox), data = df, method.inference = "none", trace = 0)
#+END_SRC

#+RESULTS:
:  endpoint threshold  delta  Delta
:       tox     1e-12 0.8359 0.8359

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
d <- (meanY-meanX)/sdXY
2*pnorm(d/sqrt(2))-1
#+END_SRC

#+RESULTS:
: [1] 0.8427008

\clearpage

* Survival

** Theory
For a given cumulative density function \(F(x)\) and a corresponding
probability density function \(f(x)\) we define the hazard by:
#+BEGIN_EXPORT latex
\begin{align*}
\lambda(t) &=  \left. \frac{\Prob[t\leq T \leq t+h|T\geq t]}{h}\right|_{h \rightarrow 0^+} \\
&= \left. \frac{\Prob[t\leq T \leq t+h]}{\Prob[T\geq t]h}\right|_{h \rightarrow 0^+} \\
&= \frac{f(t)}{1-F(t)}
\end{align*}
#+END_EXPORT

\bigskip

Let now consider two times to events following an exponential distribution:
- \(X \sim Exp(\alpha_1)\). The corresponding hazard function is \(\lambda(t)=\alpha_1\).
- \(Y \sim Exp(\alpha_2)\). The corresponding hazard function is \(\lambda(t)=\alpha_2\).
So the hazad ratio is \(HR = \frac{\lambda_2}{\lambda_1}\). Note that if we use a cox model we will have:
#+BEGIN_EXPORT latex
\begin{align*}
\lambda(t) = \lambda_0(t) \exp(\beta \Ind[group])
\end{align*}
#+END_EXPORT
where \(\exp(\beta)\) is the hazard ratio.

\bigskip

#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y>X] &= \int_{0}^{\infty}\alpha_1 \exp(-\alpha_1 x)  \int_x^{\infty} \alpha_2 \exp(-\alpha_2 y) dy dx \\
&= \int_{0}^{\infty}\alpha_1 \exp(-\alpha_1 x)  [ \exp(-\alpha_2 y) ]_{\infty}^{x} dx \\
&= \int_{0}^{\infty}\alpha_1 \exp(-\alpha_1 x) \exp(-\alpha_2 x) dx \\
&= \frac{\alpha_1}{\alpha_1+\alpha_2} [\exp(-(\alpha_1+\alpha_2) x)]_{\infty}^{0} \\
&= \frac{\alpha_1}{\alpha_1+\alpha_2}\\
&= \frac{1}{1+HR}\\
\end{align*}
#+END_EXPORT

So:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = 2\frac{1}{1+HR}-1 = \frac{1-HR}{1+HR}
\end{align*}
#+END_EXPORT

** In R

Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alphaX <- 2
alphaY <- 1
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(time = rexp(n, rate = alphaX), group = "C", event = 1),
            data.frame(time = rexp(n, rate = alphaY), group = "T", event = 1))
#+END_SRC

#+RESULTS:

Buyse test:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
BuyseTest(group ~ tte(time, censoring = event), data = df,
          method.inference = "none", trace = 0, method.tte = "Gehan")
#+END_SRC
#+RESULTS:
:  endpoint threshold  delta  Delta
:      time     1e-12 0.3403 0.3403

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.coxph <- coxph(Surv(time,event)~group,data = df)
HR <- as.double(exp(coef(e.coxph)))
c("HR" = alphaY/alphaX, "Delta" = 2*alphaX/(alphaY+alphaX)-1)
c("HR.cox" = HR, "Delta" = (1-HR)/(1+HR))
#+END_SRC

#+RESULTS:
:        HR     Delta 
: 0.5000000 0.3333333
:    HR.cox     Delta 
: 0.4918256 0.3406392

\clearpage

* Competing risks

** Theory

*** General case (no censoring)
Let consider: 
- \(X^*_{E}\) the time to the occurrence of the event of interest in the control group.
- \(Y^*_{E}\) the time to the occurrence of the event of interest in the treatment group.
- \(X^*_{CR}\) the time to the occurrence of the competing event of interest in the control group.
- \(Y^*_{CR}\) the time to the occurrence of the competing event of interest in the treatment group.
Let denote \(\varepsilon_X = 1 +\Ind[X^*_{E} > X^*_{CR}]\) the event type
indicator in the control group and \(\varepsilon_Y = 1 + \Ind[Y^*_{E} >
Y^*_{CR}]\) the event type indicator in treatment group (\(=1\) when the
cause of interest is realised first and 2 when the competing risk is
realised first).

\bigskip

For each subject either the event of interest or the competing event
is realized. We now define:
#+BEGIN_EXPORT latex
\begin{align*}
X = \left\{
              \begin{array}{ll}
                 X^*_{E} \text{ if }\varepsilon_X = 1  \\
                 +\infty \text{ if }\varepsilon_X = 2 
                \end{array}
              \right.
\text{ and }
Y = \left\{
              \begin{array}{ll}
                 Y^*_{E} \text{ if }\varepsilon_Y = 1  \\
                 +\infty \text{ if }\varepsilon_Y = 2 
                \end{array}
              \right.
\end{align*}
#+END_EXPORT
i.e. when the event of interest is not realized we say that the time to event is infinite.

\bigskip

We thus have:
#+BEGIN_EXPORT latex
\begin{align*}
\Prob[Y > X] 
= & \Prob[Y > X|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] \\
&+ \Prob[Y > X|\varepsilon_X=1,\varepsilon_Y=2]\Prob[\varepsilon_X=1,\varepsilon_Y=2] \\
&+ \Prob[Y > X|\varepsilon_X=2,\varepsilon_Y=1]\Prob[\varepsilon_X=2,\varepsilon_Y=1] \\
&+ \Prob[Y > X|\varepsilon_X=2,\varepsilon_Y=2]\Prob[\varepsilon_X=2,\varepsilon_Y=2] \\
= & \Prob[Y > X|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] \\
&+ 1*\Prob[\varepsilon_X=1,\varepsilon_Y=2] \\
&+ 0*\Prob[\varepsilon_X=2,\varepsilon_Y=1] \\
&+ 0*\Prob[\varepsilon_X=2,\varepsilon_Y=2] \\
\end{align*}
#+END_EXPORT

So \(\Prob[X > Y] = \Prob[X >
Y|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] +
\Prob[\varepsilon_X=1,\varepsilon_Y=2] \) and:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta = &
 \big(\Prob[X > Y|\varepsilon_X=1,\varepsilon_Y=1] - \Prob[X < Y|\varepsilon_X=1,\varepsilon_Y=1] \big) \Prob[\varepsilon_X=1,\varepsilon_Y=1] \\
& + \Prob[\varepsilon_X=1,\varepsilon_Y=2] - \Prob[\varepsilon_X=2,\varepsilon_Y=1]
\end{align*}
#+END_EXPORT

*** General case (censoring, method: Gehan)
In case of censoring we can use an inverse probability weighting
approach. For a given individual \(i\) let denote \(\delta_{c,i}\) the
indicator of no censoring, \(\tilde{X}_E\) and \(\tilde{Y}_E\) the
censored event time. We can use inverse probability weighting to
compute the net benefit:
#+BEGIN_EXPORT latex
\begin{align*}
\Delta_i^{IPW} &= \frac{\delta_{c,i}}{\Prob[\delta_c]} (\Ind[Y_{i}>X_{i}]-\Ind[Y_{i}<X_i])\\
&= \left\{
                \begin{array}{ll}
                  \frac{1}{\Prob[\delta_c]} (\Ind[\tilde{Y}_i>\tilde{X}_i]-\Ind[\tilde{Y}_i<\tilde{X}_i])\text{, if no censoring}\\
                  0\text{, if censoring}
                \end{array}
              \right.
\end{align*}
#+END_EXPORT

This is equivalent to weight the informative pairs (i.e. favorable,
unfavorable and neutral) by the inverse of the complement of the
probability of being uninformative. This is what is done by the
argument =correction.tte= of =BuyseTest=. This works whenever the
censoring mechanism is independent of the event times and we have a
consistent estimate of \(\Prob[\delta_c]\) since:
#+BEGIN_EXPORT latex
\begin{align*}
\Esp[\Delta_i^{IPW}] &= \Esp\left[\frac{\delta_{c,i}}{\Prob[\delta_c]} (\Ind[Y_{i}>X_{i}]-\Ind[Y_{i}<X_{i}])\right]\\
&= \Esp\left[\frac{\delta_{c,i}}{\Prob[\delta_c]}\right] \Esp\left[(\Ind[Y_{i}>X_{i}]-\Ind[Y_{i}<X_{i}])\right]\\
&= \frac{\Esp[\delta_{c,i}]}{\Prob[\delta_c]} \Delta\\
&= \Delta\\
\end{align*}
#+END_EXPORT


*** Exponential distribution (no censoring)

Now let's assume that:
- \(X_{E} \sim Exp(\alpha_{E,X})\).
- \(Y_{E} \sim Exp(\alpha_{E,Y})\).
- \(X_{CR} \sim Exp(\alpha_{CR,X})\).
- \(Y_{CR} \sim Exp(\alpha_{CR,Y})\).

Then:
#+BEGIN_EXPORT latex
\begin{align*}
 \Prob[Y_{E} > X_{E}] &= \Prob[Y_{E} >
X_{E}|\varepsilon_X=1,\varepsilon_Y=1]\Prob[\varepsilon_X=1,\varepsilon_Y=1] +
\Prob[\varepsilon_X=1,\varepsilon_Y=2] \\
&= \frac{1}{(\alpha_{E,X}+\alpha_{CR,X})(\alpha_{E,Y}+\alpha_{CR,Y})} \left(
 \alpha_{E,X}\alpha_{E,Y} \frac{\alpha_{E,X}}{\alpha_{E,X}+\alpha_{E,Y}}
+ \alpha_{E,X}\alpha_{CR,Y} \right) \\
\end{align*}
#+END_EXPORT


Just for comparison let's compare to the cumulative incidence. First
we only consider one group and two competing events whose times to
event follow an exponential distribution:
- \(T_E \sim Exp(\alpha_E)\). The corresponding hazard function is \(\lambda(t)=\alpha_E\).
- \(T_{CR} \sim Exp(\alpha_{CR})\). The corresponding hazard function is \(\lambda(t)=\alpha_{CR}\).
The cumulative incidence function can be written:
#+BEGIN_EXPORT latex
\begin{align*}
CIF_1(t) &= \int_0^t \lambda_1(s) S(s_-) ds \\
&= \int_0^t \alpha_E \exp(- (\alpha_E + \alpha_{CR}) * s_-) ds \\
&= \frac{\alpha_E}{\alpha_E + \alpha_{CR}} \left[ \exp(- (\alpha_E + \alpha_{CR}) * s_-)\right]_t^0 \\
&= \frac{\alpha_E}{\alpha_E + \alpha_{CR}} \left(1 - \exp(- (\alpha_E + \alpha_{CR}) * t_-)\right) 
\end{align*}
#+END_EXPORT
where \(S(t)\) denote the event free survival and \(s_-\) denotes the right sided limit.

\bigskip

Then applying this formula in the case of two groups gives:
#+BEGIN_EXPORT latex
\begin{align*}
CIF_1(t|group = X) &= \frac{\alpha_{E,X}}{\alpha_{E,X} + \alpha_{CR,X}} \left(1 - \exp(- (\alpha_{E,X} + \alpha_{CR,X}) * t_-)\right) \\
CIF_1(t|group = Y) &= \frac{\alpha_{E,Y}}{\alpha_{E,Y} + \alpha_{CR,Y}} \left(1 - \exp(- (\alpha_{E,Y} + \alpha_{CR,Y}) * t_-)\right) 
\end{align*}
#+END_EXPORT

** In R

*** BuyseTest (no censoring)

Setting:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alphaE.X <- 2
alphaCR.X <- 1
alphaE.Y <- 3
alphaCR.Y <- 2
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- rbind(data.frame(time1 = rexp(n, rate = alphaE.X), time2 = rexp(n, rate = alphaCR.X), group = "1"),
            data.frame(time1 = rexp(n, rate = alphaE.Y), time2 = rexp(n, rate = alphaCR.Y), group = "2"))
df$time <- pmin(df$time1,df$time2) ## first event
df$event <- (df$time2<df$time1)+1 ## type of event
#+END_SRC

#+RESULTS:

BuyseTest:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.BT <- BuyseTest(group ~ tte(time, censoring = event), data = df,
                  method.inference = "none", method.tte = "Gehan",
                  trace = 0)
summary(e.BT, percentage = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example
        Generalized pairwise comparison with 1 prioritized endpoint

 > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
 > null hypothesis : Delta == 0 
 > treatment groups: 1 (control) vs. 2 (treatment) 
 > censored pairs  : uninformative pairs

 > results
 endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
     time     1e-12   100      41.6       45.12   13.28     0 -0.0352 -0.0352
#+end_example

Note that without censoring one can get the same results by treating
time as a continuous variable that take value \(\infty\) when the
competing risk is observed:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
df$timeXX <- df$time
df$timeXX[df$event==2] <- max(df$time)+1
e.BT.bis <- BuyseTest(group ~ cont(timeXX), data = df,
                  method.inference = "none", trace = 0)
summary(e.BT.bis, percentage = TRUE)
#+END_SRC

#+RESULTS:
:         Generalized pairwise comparison with 1 prioritized endpoint
: 
:  > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
:  > null hypothesis : Delta == 0 
:  > treatment groups: 1 (control) vs. 2 (treatment) 
:  > results
:  endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
:    timeXX     1e-12   100      41.6       45.12   13.28     0 -0.0352 -0.0352

Expected:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
weight <- (alphaE.X+alphaCR.X)*(alphaE.Y+alphaCR.Y)
exp <- list()
exp$favorable <- 1/weight*(alphaE.X*alphaE.Y*alphaE.X/(alphaE.X+alphaE.Y)+(alphaE.X*alphaCR.Y))
exp$unfavorable <- 1/weight*(alphaE.X*alphaE.Y*alphaE.Y/(alphaE.X+alphaE.Y)+(alphaE.Y*alphaCR.X))
exp$neutral <- alphaCR.X*alphaCR.Y/weight

100*unlist(exp)
#+END_SRC

#+RESULTS:
:   favorable unfavorable     neutral 
:    42.66667    44.00000    13.33333

# Subdistributional hazard:
# #+BEGIN_SRC R :exports both :results output :session *R* :cache no
# e.coxph <- coxph(Surv(timeXX, event>0) ~ group, data = df)
# HR.coxph <- as.double(exp(coef(e.coxph)))
# c("HR.sub" = HR.coxph, "Delta.sub" = (1-HR.coxph)/(1+HR.coxph))
# #+END_SRC

# #+RESULTS:
# :     HR.sub  Delta.sub 
# : 0.97182195 0.01429036

*** BuyseTest (with censoring)

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
df$eventC <- df$event
df$eventC[rbinom(n, size = 1, prob = 0.2)==1] <- 0
#+END_SRC

#+RESULTS:

BuyseTest (biased):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.BTC <- BuyseTest(group ~ tte(time, censoring = eventC), data = df,
                   method.inference = "none", method.tte = "Gehan",
                   trace = 0)
summary(e.BTC, percentage = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example
        Generalized pairwise comparison with 1 prioritized endpoint

 > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
 > null hypothesis : Delta == 0 
 > treatment groups: 1 (control) vs. 2 (treatment) 
 > censored pairs  : uninformative pairs

 > results
 endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
     time     1e-12   100      31.1       35.15    8.65  25.1 -0.0406 -0.0406
#+end_example

BuyseTest (unbiased):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.BTCC <- BuyseTest(group ~ tte(time, censoring = eventC), data = df,
                   method.inference = "none", method.tte = "Gehan corrected",
                   trace = 0)
summary(e.BTCC, percentage = TRUE)
#+END_SRC

#+RESULTS:
#+begin_example
        Generalized pairwise comparison with 1 prioritized endpoint

 > statistic       : net chance of a better outcome (delta: endpoint specific, Delta: global) 
 > null hypothesis : Delta == 0 
 > treatment groups: 1 (control) vs. 2 (treatment) 
 > censored pairs  : uninformative pairs
                     IPW for uninformative pairs

 > results
 endpoint threshold total favorable unfavorable neutral uninf   delta   Delta
     time     1e-12   100     41.52       46.94   11.54     0 -0.0542 -0.0542
#+end_example

*** Cumulative incidence

Settings:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
alphaE <- 2
alphaCR <- 1
#+END_SRC

#+RESULTS:

Simulate data:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df <- data.frame(time1 = rexp(n, rate = alphaE), time2 = rexp(n, rate = alphaCR), group = "1", event = 1)
df$time <- pmin(df$time1,df$time2)
df$event <- (df$time2<df$time1)+1
#+END_SRC

#+RESULTS:

Cumulative incidence (via risk regression):
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.CSC <- CSC(Hist(time, event) ~ 1, data = df)
vec.times <- unique(round(exp(seq(log(min(df$time)),log(max(df$time)),length.out = 12)),2))
e.CSCpred <- predict(e.CSC, newdata = data.frame(X = 1), time = vec.times , cause = 1)
#+END_SRC

#+RESULTS:

Expected vs. calculated:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
cbind(time = vec.times,
      CSC = e.CSCpred$absRisk[1,],
      manual = alphaE/(alphaE+alphaCR)*(1-exp(-(alphaE+alphaCR)*(vec.times)))
      )
#+END_SRC

#+RESULTS:
:      time    CSC     manual
: [1,] 0.00 0.0000 0.00000000
: [2,] 0.01 0.0186 0.01970298
: [3,] 0.02 0.0377 0.03882364
: [4,] 0.05 0.0924 0.09286135
: [5,] 0.14 0.2248 0.22863545
: [6,] 0.42 0.4690 0.47756398
: [7,] 1.24 0.6534 0.65051069
: [8,] 3.70 0.6703 0.66665659

Could also be obtained treating the outcome as binary:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
mean((df$time<=1)*(df$event==1))
#+END_SRC

#+RESULTS:
: [1] 0.6375


# * References
# bibliographystyle:apalike
# [[bibliography:bibliography.bib]]

# @@latex:any arbitrary LaTeX code@@




* CONFIG :noexport:
# #+LaTeX_HEADER:\affil{Department of Biostatistics, University of Copenhagen, Copenhagen, Denmark}
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+OPTIONS:   title:t author:t toc:t todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t

** Code
#+PROPERTY: header-args :session *R*
#+PROPERTY: header-args :tange yes % extract source code: http://orgmode.org/manual/Extracting-source-code.html
#+PROPERTY: header-args :cache no
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}

** Display 
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\usepackage{authblk} % enable several affiliations (clash with beamer)

** Image
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files

** Latex command
#+LaTeX_HEADER: %
#+LaTeX_HEADER: %%%% additional latex commands %%%%
#+LaTeX_HEADER: %

** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}

** Math
#+LATEX_HEADER: \RequirePackage{ifthen}
#+LATEX_HEADER: \RequirePackage{xspace} % space for newcommand macro
#+LATEX_HEADER: \RequirePackage{xifthen}
#+LATEX_HEADER: \RequirePackage{xargs}
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)

# ## lemma
#+LaTeX_HEADER: \RequirePackage{amsthm}
#+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
#+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}

*** Template for shortcut
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }

*** Shortcuts

**** Probability
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}

#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}

#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}

**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}

#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}

#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }

#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}

#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\left( \partial #2\right)^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 

**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
