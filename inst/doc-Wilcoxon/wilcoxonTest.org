#+TITLE: Wilcoxon test via GPC
#+Author: Brice Ozenne

#+BEGIN_SRC R :exports none :results quiet :session *R* :cache no
library(BuyseTest)
library(asht)
library(pbapply)
library(riskRegression)
BuyseTest.options(trace=0)
#+END_SRC

#+RESULTS:

Generalized Pairwise comparisons (GPC) include the Wilcoxon rank sum
test as a specific case. This vignette explores the connections
between the =BuyseTest= output and the more standard implementation of
the wilcoxon-test.


* Single Wilcoxon test

** Exact test

Consider the first 'two sample test' example from the help page section of =stats::wilcox.test=:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
x <- c(0.80, 0.83, 1.89, 1.04, 1.45, 1.38, 1.91, 1.64, 0.73, 1.46)
y <- c(1.15, 0.88, 0.90, 0.74, 1.21)
df <- rbind(data.frame(value = x, group="x"),
            data.frame(value = y, group="y"))
#+END_SRC

#+RESULTS:

\noindent We can perform a Wilcoxon test using the =wilcox.test= function:

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
wilcox.test(value ~ group, data = df)
#+END_SRC

#+RESULTS:
: 
: 	Wilcoxon rank sum exact test
: 
: data:  value by group
: W = 35, p-value = 0.2544
: alternative hypothesis: true location shift is not equal to 0

which, with such a small sample, can perform an exact test, i.e.,
consider all possible permutation of the group variable. It
unfortunately does not ouput any effect size (just the test statistic
and corresponding p-value). The package /asht/ contains an alternative
implementation:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
asht::wmwTest(value ~ group, data = df, method = "exact.ce")
#+END_SRC

#+RESULTS:
#+begin_example

	exact Wilcoxon-Man-Whitney test (confidence interval requires proportional odds
	assumption, but test does not)

data:  value by group
Mann-Whitney estimate = 0.3, p-value = 0.2544
alternative hypothesis: two distributions are not equal
95 percent confidence interval:
 0.08292978 0.63269022
sample estimates:
Mann-Whitney estimate 
                  0.3
#+end_example

\noindent which output an estimate, the probability that a randomly
chosen observation from one group has higher value than a randomly
chosen observation from the other group, which is refered to as
Mann-Whitney parameter or probabilistic index. To match those results
with GPC we can use a permutation test: \newline \Warning the argument
=add.halfNeutral= should be set to =TRUE= to adequatly handle ties
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eperm.BT <- BuyseTest(group ~ cont(value), data = df, add.halfNeutral = TRUE,
                      method.inference = "permutation", n.resampling = 1e4,
                      trace = FALSE, cpus = 5, seed = 10)
confint(eperm.BT, statistic = "favorable")
#+END_SRC

#+RESULTS:
:       estimate        se lower.ci upper.ci null   p.value
: value      0.3 0.1632342       NA       NA  0.5 0.2566743

Up to the Monte Carlo error for the p-value calculation, which can be
made arbitrarily small by increasing the number of permutations
(argument =n.resampling=), the resuls are identical. Note that the
'default' statistical inference method based on asymptotic
U-statistic theory:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eU.BT <- suppressWarnings(BuyseTest(group ~ cont(value), data = df,
                                    add.halfNeutral = TRUE))
confint(eU.BT, statistic = "favorable")
#+END_SRC

#+RESULTS:
:       estimate        se  lower.ci  upper.ci null  p.value
: value      0.3 0.1334166 0.1098282 0.5981833  0.5 0.182315

\noindent leads to a different p-value as a different null hypothesis
is being tested here: probabilistic index equal 0.5 instead of
equality in distribution. This p-value corresponds, up to some small
sample approximation and the Monte Carlo error, to the one obtain with
a studentized permutation:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
etperm.BT <- BuyseTest(group ~ cont(value), data = df, add.halfNeutral = TRUE,
                      method.inference = "studentized permutation", n.resampling = 1e4,
                      trace = FALSE, seed = 10)
confint(etperm.BT, statistic = "favorable")
#+END_SRC

#+RESULTS:
:       estimate        se lower.ci upper.ci null   p.value
: value      0.3 0.1334166       NA       NA  0.5 0.1916808

** Approximate test

Consider now a bigger (artificial) dataset:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(10)
df2 <- rbind(data.frame(value = round(rnorm(50),2), group="x"),
             data.frame(value = round(rnorm(50),2), group="y"))
any(duplicated(df2$value)) ## test whether there are any ties
#+END_SRC

#+RESULTS:
: [1] TRUE

We can again perform a Wilcoxon test using the =wilcox.test= function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
wilcox.test(value ~ group, data = df2)
#+END_SRC

#+RESULTS:
: 
: 	Wilcoxon rank sum test with continuity correction
: 
: data:  value by group
: W = 967.5, p-value = 0.05188
: alternative hypothesis: true location shift is not equal to 0

or, equivalenty, with the =wmwTest= function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
wmwTest(value ~ group, data = df2)
#+END_SRC

#+RESULTS:
#+begin_example

	Wilcoxon-Mann-Whitney test with continuity correction (confidence
	interval requires proportional odds assumption, but test does not)

data:  value by group
Mann-Whitney estimate = 0.613, tie factor = 0.99995, p-value = 0.05188
alternative hypothesis: two distributions are not equal
95 percent confidence interval:
 0.4990803 0.7138973
sample estimates:
Mann-Whitney estimate 
                0.613
#+end_example

In either case, an exact test would be too computationally demanding
and an approximate test is performed instead, which assumes a normaly
distributed test statistic. The BuyseTest package will not be able to
match these results due to the continuity correction. Without
continuity correction, e.g.:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
wmwTest(value ~ group, data = df2, correct = FALSE)
#+END_SRC

#+RESULTS:
#+begin_example

	Wilcoxon-Mann-Whitney test (confidence interval requires proportional odds
	assumption, but test does not)

data:  value by group
Mann-Whitney estimate = 0.613, tie factor = 0.99995, p-value = 0.05147
alternative hypothesis: two distributions are not equal
95 percent confidence interval:
 0.4992803 0.7137196
sample estimates:
Mann-Whitney estimate 
                0.613
#+end_example

\noindent it is possible to retrieve the exact same p-value by
evaluating the variance of the permutation distribution and assuming a
normally distributed test statistic. In this simple example this can
be done using an analytic formula citep:anderson2023exact: \newline
\Warning the code, kindly provided by the authors of the paper, has
been ported to the package with minimal change. It is therefore meant
to be used in the context of the original publication and not in the
more general setting covered by the package (strata, right-censoring,
\ldots)
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eperm.BT2 <- BuyseTest(group ~ cont(value), data = df2, add.halfNeutral = TRUE,
                       method.inference = "varexact-permutation")
confint(eperm.BT2, statistic = "favorable")
#+END_SRC

#+RESULTS:
:       estimate         se lower.ci upper.ci null    p.value
: value    0.613 0.05802219       NA       NA  0.5 0.05147115

or, more generally, using a resampling method:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
eperm.BT2 <- BuyseTest(group ~ cont(value), data = df2, add.halfNeutral = TRUE,
                       method.inference = "permutation", n.resampling = 1e4,
                       trace = FALSE, cpus = 5, seed = 10)
confint(eperm.BT2, statistic = "favorable", method.ci.resampling = "gaussian")
#+END_SRC

#+RESULTS:
:       estimate         se lower.ci upper.ci null    p.value
: value    0.613 0.05814569       NA       NA  0.5 0.05118099

\clearpage

* Multiple Wilcoxon tests

Consider now the case where we would like to compare one reference
group (here strata =a=) to multiple treatment groups (here strata
=b,c,d,e=). We will consider the following dataset:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
set.seed(35)
dt <- simBuyseTest(n.T=25, n.strata = 5)
dt$id <- paste0("id",1:NROW(dt))
dt$strata <- as.character(dt$strata) 
print(head(dt), class = FALSE)
#+END_SRC

#+RESULTS:
:     id treatment  eventtime status toxicity      score strata
: 1: id1         C 0.03384999      1      yes  0.4777913      b
: 2: id2         C 0.65039474      0       no -1.1048190      d
: 3: id3         C 1.00647502      1       no -0.1407630      b
: 4: id4         C 0.01129603      1      yes -0.5512507      a
: 5: id5         C 0.22249748      1       no  1.0465250      d
: 6: id6         C 0.07400412      0       no -2.0053855      d

We can apply the GPC procedure to each pair of group:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
BuyseTest.options(order.Hprojection=1);BuyseTest.options(trace=0)

ls.BT <- list("b-a=0" = BuyseTest(strata ~ cont(score), add.halfNeutral = TRUE,
                                  data = dt[dt$strata %in% c("a","b"),],
                                  method.inference = "u-statistic"),
              "c-a=0" = BuyseTest(strata ~ cont(score), add.halfNeutral = TRUE,
                                  data = dt[dt$strata %in% c("a","c"),],
                                  method.inference = "u-statistic"),
              "d-a=0" = BuyseTest(strata ~ cont(score), add.halfNeutral = TRUE,
                                  data = dt[dt$strata %in% c("a","d"),],
                                  method.inference = "u-statistic"),
              "e-a=0" = BuyseTest(strata ~ cont(score), add.halfNeutral = TRUE,
                                  data = dt[dt$strata %in% c("a","e"),],
                                  method.inference = "u-statistic")
              )

M.confint <- do.call(rbind,lapply(ls.BT,confint, statistic = "favorable"))
cbind(M.confint,adj.p.value = p.adjust(M.confint[,"p.value"], method = "bonferroni"))
#+END_SRC

#+RESULTS:
:        estimate        se  lower.ci  upper.ci null    p.value adj.p.value
: b-a=0 0.4090909 0.1542200 0.1654639 0.7073759  0.5 0.56434599   1.0000000
: c-a=0 0.4375000 0.1465755 0.1948678 0.7142379  0.5 0.67306460   1.0000000
: d-a=0 0.2500000 0.1010153 0.1039078 0.4893302  0.5 0.04143057   0.1657223
: e-a=0 0.3333333 0.1360828 0.1308601 0.6241219  0.5 0.25767454   1.0000000


Because we compare the treatment groups to the same reference, the
test statistics are correlated and a Bonferroni adjustment does not
provide optimal power. The max-test adjustment provides better power
and can be obtained via the =BuyseMultComp= function:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
e.mc <- BuyseMultComp(ls.BT, statistic = "favorable", cluster = "id", global = TRUE)
print(e.mc, cols = c("estimate","se","p.value","adj.p.value"))
#+END_SRC

#+RESULTS:
:   - Multivariate test: p.value = 0.2645493 (df = 4)
:   - Univariate tests:
:        estimate        se    p.value adj.p.value
: b-a=0 0.4090909 0.1542200 0.56434599   0.9289219
: c-a=0 0.4375000 0.1465755 0.67306460   0.9752151
: d-a=0 0.2500000 0.1010153 0.04143057   0.1223430
: e-a=0 0.3333333 0.1360828 0.25767454   0.5831344


Here the smallest p-value has been multiplied by a factor 2.64 instead
of 4. This is thanks to the rather strong correlation between the test
statistics:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
M.cor <- cor(lava::iid(e.mc))
dimnames(M.cor) <- list(names(ls.BT),names(ls.BT))
M.cor
#+END_SRC

#+RESULTS:
:           b-a=0     c-a=0     d-a=0     e-a=0
: b-a=0 1.0000000 0.6519486 0.5601058 0.7520401
: c-a=0 0.6519486 1.0000000 0.4240003 0.5439927
: d-a=0 0.5601058 0.4240003 1.0000000 0.5051815
: e-a=0 0.7520401 0.5439927 0.5051815 1.0000000

\Warning This testing procedure does not guarantee transitive results citep:thangavelu2007wilcoxon


* References
:PROPERTIES:
:UNNUMBERED: t
:END:

#+BEGIN_EXPORT latex
\begingroup
\renewcommand{\section}[2]{}
#+END_EXPORT

bibliographystyle:apalike
[[bibliography:bibliography.bib]]

#+BEGIN_EXPORT latex
\endgroup
#+END_EXPORT

* CONFIG :noexport:
# #+LaTeX_HEADER:\affil{Department of Biostatistics, University of Copenhagen, Copenhagen, Denmark}
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t
** Display of the document
# ## space between lines
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}
# ## margins
#+LaTeX_HEADER: \geometry{a4paper, left=10mm, right=10mm, top=10mm}
# ## personalize the prefix in the name of the sections
#+LaTeX_HEADER: \usepackage{titlesec}
# ## fix bug in titlesec version
# ##  https://tex.stackexchange.com/questions/299969/titlesec-loss-of-section-numbering-with-the-new-update-2016-03-15
#+LaTeX_HEADER: \usepackage{etoolbox}
#+LaTeX_HEADER: 
#+LaTeX_HEADER: \makeatletter
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\parindent\z@}{\parindent\z@\leavevmode}{}{}
#+LaTeX_HEADER: \patchcmd{\ttlh@hang}{\noindent}{}{}{}
#+LaTeX_HEADER: \makeatother
** Color
# ## define new colors
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LaTeX_HEADER: \definecolor{myorange}{rgb}{1,0.2,0}
#+LaTeX_HEADER: \definecolor{mypurple}{rgb}{0.7,0,8}
#+LaTeX_HEADER: \definecolor{mycyan}{rgb}{0,0.6,0.6}
#+LaTeX_HEADER: \newcommand{\lightblue}{blue!50!white}
#+LaTeX_HEADER: \newcommand{\darkblue}{blue!80!black}
#+LaTeX_HEADER: \newcommand{\darkgreen}{green!50!black}
#+LaTeX_HEADER: \newcommand{\darkred}{red!50!black}
#+LaTeX_HEADER: \definecolor{gray}{gray}{0.5}
# ## change the color of the links
#+LaTeX_HEADER: \hypersetup{
#+LaTeX_HEADER:  citecolor=[rgb]{0,0.5,0},
#+LaTeX_HEADER:  urlcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER:  linkcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER: }
** Font
# https://tex.stackexchange.com/questions/25249/how-do-i-use-a-particular-font-for-a-small-section-of-text-in-my-document
#+LaTeX_HEADER: \newenvironment{note}{\small \color{gray}\fontfamily{lmtt}\selectfont}{\par}
#+LaTeX_HEADER: \newenvironment{activity}{\color{orange}\fontfamily{qzc}\selectfont}{\par}
** Symbols
# ## valid and cross symbols
#+LaTeX_HEADER: \RequirePackage{pifont}
#+LaTeX_HEADER: \RequirePackage{relsize}
#+LaTeX_HEADER: \newcommand{\Cross}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{56}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\Valid}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{52}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\CrossR}{ \textcolor{red}{\Cross} }
#+LaTeX_HEADER: \newcommand{\ValidV}{ \textcolor{green}{\Valid} }
# ## warning symbol
#+LaTeX_HEADER: \usepackage{stackengine}
#+LaTeX_HEADER: \usepackage{scalerel}
#+LaTeX_HEADER: \newcommand\Warning[1][3ex]{%
#+LaTeX_HEADER:   \renewcommand\stacktype{L}%
#+LaTeX_HEADER:   \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
#+LaTeX_HEADER:   \xspace
#+LaTeX_HEADER: }
# # R Software
#+LATEX_HEADER: \newcommand\Rlogo{\textbf{\textsf{R}}\xspace} % 
** Code
:PROPERTIES:
:ID:       2ec77c4b-f83d-4612-9a89-a96ba1b7bf70
:END:
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*
# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
# ## change font size input (global change)
# ## doc: https://ctan.math.illinois.edu/macros/latex/contrib/listings/listings.pdf
# #+LATEX_HEADER: \newskip kipamount    kipamount =6pt plus 0pt minus 6pt
# #+LATEX_HEADER: \lstdefinestyle{code-tiny}{basicstyle=\ttfamily\tiny, aboveskip =  kipamount, belowskip =  kipamount}
# #+LATEX_HEADER: \lstset{style=code-tiny}
# ## change font size input (local change, put just before BEGIN_SRC)
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output (global change)
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}
** Lists
#+LATEX_HEADER: \RequirePackage{enumitem} % better than enumerate
** Image and graphs
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics
#+LaTeX_HEADER: \RequirePackage{tikz-cd} % graph
# ## https://tools.ietf.org/doc/texlive-doc/latex/tikz-cd/tikz-cd-doc.pdf
** Table
#+LATEX_HEADER: \RequirePackage{booktabs} % for nice lines in table (e.g. toprule, bottomrule, midrule, cmidrule)
** Inline latex
# @@latex:any arbitrary LaTeX code@@
** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}
** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)
# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
*** Template for shortcut
#+LATEX_HEADER: \usepackage{ifthen}
#+LATEX_HEADER: \usepackage{xifthen}
#+LATEX_HEADER: \usepackage{xargs}
#+LATEX_HEADER: \usepackage{xspace}
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }
**** Probability
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\logLikelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\partial #2^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 
**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
#+LATEX_HEADER: \newcommand\Veta{\boldsymbol{\eta}}
#+LATEX_HEADER: \newcommand\VX{\mathbf{X}}
** Notations



